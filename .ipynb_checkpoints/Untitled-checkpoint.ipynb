{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815114f9-37ee-42e9-89ac-9c4797422d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Depression'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 120\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel saved as: depression_prediction_xgboost.model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 102\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    101\u001b[0m processed_train, encoders, scaler, pca \u001b[38;5;241m=\u001b[39m preprocess_data(train_data, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 102\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m processed_test, _, _, _ \u001b[38;5;241m=\u001b[39m preprocess_data(test_data, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoders\u001b[38;5;241m=\u001b[39mencoders, scaler\u001b[38;5;241m=\u001b[39mscaler, pca\u001b[38;5;241m=\u001b[39mpca)\n\u001b[0;32m    105\u001b[0m train_cols \u001b[38;5;241m=\u001b[39m processed_train\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepression\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(train_data):\n\u001b[1;32m---> 72\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDepression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     y \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepression\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     74\u001b[0m     X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Depression'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def encode_categorical(series, is_train=True, mapping=None):\n",
    "    if is_train:\n",
    "        unique_values = series.unique()\n",
    "        mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    max_val = max(mapping.values()) if mapping else 0\n",
    "    return series.map(lambda x: mapping.get(x, max_val + 1)), mapping\n",
    "\n",
    "def preprocess_data(df, is_train=True, encoders=None, scaler=None, pca=None):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Separate target variable if exists\n",
    "    target = None\n",
    "    if 'Depression' in df.columns:\n",
    "        target = df['Depression']\n",
    "        df = df.drop('Depression', axis=1)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    cols_to_drop = ['id', 'Name']\n",
    "    df = df.drop([col for col in cols_to_drop if col in df.columns], axis=1)\n",
    "    \n",
    "    # Initialize encoders and scalers if training\n",
    "    if is_train:\n",
    "        encoders = {}\n",
    "        scaler = StandardScaler()\n",
    "        pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "    \n",
    "    # Process categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        df[column], mapping = encode_categorical(df[column].astype(str), is_train=is_train, mapping=encoders.get(column))\n",
    "        if is_train:\n",
    "            encoders[column] = mapping\n",
    "    \n",
    "    # Handle numeric variables\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    # Feature Engineering\n",
    "    # 1. Polynomial Features\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    poly_features = poly.fit_transform(df[numeric_columns])\n",
    "    poly_columns = [f'poly_{i}' for i in range(poly_features.shape[1])]\n",
    "    df_poly = pd.DataFrame(poly_features, columns=poly_columns)\n",
    "    df = pd.concat([df, df_poly], axis=1)\n",
    "    \n",
    "    # 2. Clustering Features\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    df['cluster'] = kmeans.fit_predict(df[numeric_columns])\n",
    "    \n",
    "    # 3. Ratio Features\n",
    "    if {'SleepHrs', 'WorkHrs'}.issubset(df.columns):\n",
    "        df['Sleep_Work_Ratio'] = df['SleepHrs'] / (df['WorkHrs'] + 1)\n",
    "    \n",
    "    # 4. Standard Scaling\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    # 5. Dimensionality Reduction\n",
    "    df_reduced = pca.fit_transform(df_scaled)\n",
    "    df_final = pd.DataFrame(df_reduced)\n",
    "    \n",
    "    # Reattach target variable if present\n",
    "    if target is not None:\n",
    "        df_final['Depression'] = target.values\n",
    "    \n",
    "    return df_final, encoders, scaler, pca\n",
    "\n",
    "def train_model(train_data):\n",
    "    X = train_data.drop('Depression', axis=1)\n",
    "    y = train_data['Depression']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'max_depth': 5,\n",
    "        'learning_rate': 0.005,\n",
    "        'subsample': 0.9,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'n_estimators': 5000,\n",
    "        'verbosity': 0,\n",
    "        'early_stopping_rounds': 50,\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n",
    "    val_predictions = model.predict(X_val)\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y_val, val_predictions):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    processed_train, encoders, scaler, pca = preprocess_data(train_data, is_train=True)\n",
    "    model = train_model(processed_train)\n",
    "    processed_test, _, _, _ = preprocess_data(test_data, is_train=False, encoders=encoders, scaler=scaler, pca=pca)\n",
    "    \n",
    "    train_cols = processed_train.drop('Depression', axis=1).columns\n",
    "    processed_test = processed_test[train_cols]\n",
    "    test_predictions = model.predict(processed_test)\n",
    "    \n",
    "    submission = pd.DataFrame({'id': test_data['id'], 'Depression': test_predictions})\n",
    "    submission.to_csv('submission_xgboost.csv', index=False)\n",
    "    \n",
    "    feature_importance = pd.DataFrame({'feature': train_cols, 'importance': model.feature_importances_})\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.sort_values('importance', ascending=False).head(10))\n",
    "    \n",
    "    model.save_model('depression_prediction_xgboost.model')\n",
    "    print(\"\\nModel saved as: depression_prediction_xgboost.model\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63569e75-26e6-4a8e-9a6e-51a37fadcf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
