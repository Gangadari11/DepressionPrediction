{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f8276b-5a16-42b0-a3bb-a813dc24baf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Training data columns: ['id', 'Name', 'Gender', 'Age', 'City', 'Working Professional or Student', 'Profession', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Sleep Duration', 'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?', 'Work/Study Hours', 'Financial Stress', 'Family History of Mental Illness', 'Depression']\n",
      "Test data columns: ['id', 'Name', 'Gender', 'Age', 'City', 'Working Professional or Student', 'Profession', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', 'Job Satisfaction', 'Sleep Duration', 'Dietary Habits', 'Degree', 'Have you ever had suicidal thoughts ?', 'Work/Study Hours', 'Financial Stress', 'Family History of Mental Illness']\n",
      "\n",
      "Training model...\n",
      "\n",
      "Validation Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.96     22986\n",
      "         1.0       0.84      0.82      0.83      5154\n",
      "\n",
      "    accuracy                           0.94     28140\n",
      "   macro avg       0.90      0.89      0.90     28140\n",
      "weighted avg       0.94      0.94      0.94     28140\n",
      "\n",
      "Validation Accuracy: 0.9385\n",
      "\n",
      "Making predictions on test data...\n",
      "\n",
      "Submission file created: submission.csv\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "              feature  importance\n",
      "1                 Age        4816\n",
      "14   Work/Study Hours        2834\n",
      "15   Financial Stress        2498\n",
      "6       Work Pressure        2418\n",
      "9    Job Satisfaction        2331\n",
      "4          Profession        2106\n",
      "5   Academic Pressure        2090\n",
      "12             Degree        1780\n",
      "11     Dietary Habits        1589\n",
      "2                City        1437\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def encode_categorical(series, is_train=True, mapping=None):\n",
    "    if is_train:\n",
    "        # Create a mapping for unique values\n",
    "        unique_values = series.unique()\n",
    "        mapping = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    \n",
    "    # Transform using mapping, assign max value + 1 for unseen categories\n",
    "    max_val = max(mapping.values()) if mapping else 0\n",
    "    return series.map(lambda x: mapping.get(x, max_val + 1)), mapping\n",
    "\n",
    "def preprocess_data(df, is_train=True, encoders=None):\n",
    "    # Create a copy of the dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop ID and Name columns\n",
    "    cols_to_drop = ['id', 'Name']\n",
    "    if not is_train:\n",
    "        # For test data, also drop the Depression column if it exists\n",
    "        cols_to_drop.append('Depression')\n",
    "    df = df.drop([col for col in cols_to_drop if col in df.columns], axis=1)\n",
    "    \n",
    "    # Initialize encoders dictionary if training\n",
    "    if is_train:\n",
    "        encoders = {}\n",
    "    \n",
    "    # Process categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for column in categorical_columns:\n",
    "        if column != 'Depression':\n",
    "            df[column], mapping = encode_categorical(\n",
    "                df[column].astype(str),\n",
    "                is_train=is_train,\n",
    "                mapping=encoders.get(column)\n",
    "            )\n",
    "            if is_train:\n",
    "                encoders[column] = mapping\n",
    "    \n",
    "    # Handle numeric variables\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_columns) > 0:\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    # Convert all columns to float\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df, encoders\n",
    "\n",
    "def train_model(train_data):\n",
    "    # Separate features and target\n",
    "    X = train_data.drop('Depression', axis=1)\n",
    "    y = train_data['Depression']\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # LightGBM parameters for fast training\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.9,\n",
    "        'n_estimators': 1000,\n",
    "        'verbose': -1,\n",
    "        'early_stopping_rounds':20,\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train, \n",
    "              eval_set=[(X_val, y_val)]\n",
    "              )\n",
    "    \n",
    "    # Evaluate model\n",
    "    val_predictions = model.predict(X_val)\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    print(f\"Validation Accuracy: {accuracy_score(y_val, val_predictions):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load data\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        train_data = pd.read_csv('train.csv')\n",
    "        test_data = pd.read_csv('test.csv')\n",
    "        \n",
    "        # Print initial column names for debugging\n",
    "        print(\"\\nTraining data columns:\", train_data.columns.tolist())\n",
    "        print(\"Test data columns:\", test_data.columns.tolist())\n",
    "        \n",
    "        # Preprocess training data\n",
    "        processed_train, encoders = preprocess_data(train_data, is_train=True)\n",
    "        \n",
    "        # Train model\n",
    "        print(\"\\nTraining model...\")\n",
    "        model = train_model(processed_train)\n",
    "        \n",
    "        # Process test data using the same encoders\n",
    "        processed_test, _ = preprocess_data(test_data, is_train=False, encoders=encoders)\n",
    "        \n",
    "        # Ensure columns match between train and test\n",
    "        train_cols = processed_train.drop('Depression', axis=1).columns\n",
    "        processed_test = processed_test[train_cols]\n",
    "        \n",
    "        # Make predictions on test data\n",
    "        print(\"\\nMaking predictions on test data...\")\n",
    "        test_predictions = model.predict(processed_test)\n",
    "        \n",
    "        # Create submission file\n",
    "        submission = pd.DataFrame({\n",
    "            'id': test_data['id'],\n",
    "            'Depression': test_predictions\n",
    "        })\n",
    "        submission.to_csv('submission4.csv', index=False)\n",
    "        print(\"\\nSubmission file created: submission.csv\")\n",
    "        \n",
    "        # Print feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': train_cols,\n",
    "            'importance': model.feature_importances_\n",
    "        })\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        print(feature_importance.sort_values('importance', ascending=False).head(10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"\\nDetailed error information:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee356b-cba1-4b9a-80e1-597c048ea999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
